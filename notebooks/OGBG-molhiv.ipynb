{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "import src.GNNtrainer.models as models\n",
    "from collections import namedtuple\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For OGBG-MOLHIV\n",
    "#dataset = PygGraphPropPredDataset(name = \"ogbg-molhiv\", root = '/io/ogbg')\n",
    "# For reddit-binary\n",
    "dataset = TUDataset(root='/io/reddit', name='REDDIT-BINARY', transform=T.Constant(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on REDDIT-BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: REDDIT-BINARY(2000):\n",
      "====================\n",
      "Number of graphs: 2000\n",
      "Number of features: 1\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 480], x=[218, 1], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 218\n",
      "Number of edges: 480\n",
      "Average node degree: 2.20\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 1500\n",
      "Number of test graphs: 500\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:1500]\n",
    "test_dataset = dataset[1500:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[26406], edge_index=[2, 61042], x=[26406, 1], y=[64])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[30471], edge_index=[2, 69260], x=[30471, 1], y=[64])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[27038], edge_index=[2, 62574], x=[27038, 1], y=[64])\n",
      "\n",
      "Step 4:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[21653], edge_index=[2, 50846], x=[21653, 1], y=[64])\n",
      "\n",
      "Step 5:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[34406], edge_index=[2, 79612], x=[34406, 1], y=[64])\n",
      "\n",
      "Step 6:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[18666], edge_index=[2, 43914], x=[18666, 1], y=[64])\n",
      "\n",
      "Step 7:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[37943], edge_index=[2, 86086], x=[37943, 1], y=[64])\n",
      "\n",
      "Step 8:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[26932], edge_index=[2, 62426], x=[26932, 1], y=[64])\n",
      "\n",
      "Step 9:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[35099], edge_index=[2, 81918], x=[35099, 1], y=[64])\n",
      "\n",
      "Step 10:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[26243], edge_index=[2, 60380], x=[26243, 1], y=[64])\n",
      "\n",
      "Step 11:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[22416], edge_index=[2, 51358], x=[22416, 1], y=[64])\n",
      "\n",
      "Step 12:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[23723], edge_index=[2, 55768], x=[23723, 1], y=[64])\n",
      "\n",
      "Step 13:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[24985], edge_index=[2, 58006], x=[24985, 1], y=[64])\n",
      "\n",
      "Step 14:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[29693], edge_index=[2, 68570], x=[29693, 1], y=[64])\n",
      "\n",
      "Step 15:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[19696], edge_index=[2, 45096], x=[19696, 1], y=[64])\n",
      "\n",
      "Step 16:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[28804], edge_index=[2, 66230], x=[28804, 1], y=[64])\n",
      "\n",
      "Step 17:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[26194], edge_index=[2, 60754], x=[26194, 1], y=[64])\n",
      "\n",
      "Step 18:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[26127], edge_index=[2, 60170], x=[26127, 1], y=[64])\n",
      "\n",
      "Step 19:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[25604], edge_index=[2, 61070], x=[25604, 1], y=[64])\n",
      "\n",
      "Step 20:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[32260], edge_index=[2, 73608], x=[32260, 1], y=[64])\n",
      "\n",
      "Step 21:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[26214], edge_index=[2, 61132], x=[26214, 1], y=[64])\n",
      "\n",
      "Step 22:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[28722], edge_index=[2, 65500], x=[28722, 1], y=[64])\n",
      "\n",
      "Step 23:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "Batch(batch=[23716], edge_index=[2, 54894], x=[23716, 1], y=[64])\n",
      "\n",
      "Step 24:\n",
      "=======\n",
      "Number of graphs in the current batch: 28\n",
      "Batch(batch=[16090], edge_index=[2, 37118], x=[16090, 1], y=[28])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (emb): AtomEncoder(\n",
      "    (atom_embedding_list): ModuleList(\n",
      "      (0): Embedding(119, 9)\n",
      "      (1): Embedding(4, 9)\n",
      "      (2): Embedding(12, 9)\n",
      "      (3): Embedding(12, 9)\n",
      "      (4): Embedding(10, 9)\n",
      "      (5): Embedding(6, 9)\n",
      "      (6): Embedding(6, 9)\n",
      "      (7): Embedding(2, 9)\n",
      "      (8): Embedding(2, 9)\n",
      "    )\n",
      "  )\n",
      "  (conv1): GCNConv(1, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.emb = AtomEncoder(9)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        #x = self.emb(x)??????????????\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.      \n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y.squeeze())  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        print(pred)\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss: 0.6954443575541178\n",
      "epoch 2 loss: 0.6915993765195211\n",
      "epoch 3 loss: 0.6826803833643595\n",
      "epoch 4 loss: 0.6320986620585124\n",
      "epoch 5 loss: 0.5900826771259308\n",
      "epoch 6 loss: 0.5754357085227967\n",
      "epoch 7 loss: 0.5884442135492961\n",
      "epoch 8 loss: 0.5763287183443705\n",
      "epoch 9 loss: 0.5784719020525615\n",
      "epoch 10 loss: 0.5745966023604075\n",
      "epoch 11 loss: 0.5829605614344279\n",
      "epoch 12 loss: 0.5877226552963257\n",
      "epoch 13 loss: 0.5781127626101176\n",
      "epoch 14 loss: 0.5800930013656617\n",
      "epoch 15 loss: 0.5755476876894633\n",
      "epoch 16 loss: 0.574506546497345\n",
      "epoch 17 loss: 0.5759740679264068\n",
      "epoch 18 loss: 0.5820157322883606\n",
      "epoch 19 loss: 0.5875841024716695\n",
      "epoch 20 loss: 0.5747259953022004\n",
      "epoch 21 loss: 0.5754176880518596\n",
      "epoch 22 loss: 0.5748744239807129\n",
      "epoch 23 loss: 0.5761179342269898\n",
      "epoch 24 loss: 0.5768507223129272\n",
      "epoch 25 loss: 0.5797089120546977\n",
      "epoch 26 loss: 0.5797975963751475\n",
      "epoch 27 loss: 0.5747252044677734\n",
      "epoch 28 loss: 0.5764869771003723\n",
      "epoch 29 loss: 0.5844195675849915\n",
      "epoch 30 loss: 0.5735849744478861\n",
      "epoch 31 loss: 0.5808149205048879\n",
      "epoch 32 loss: 0.5710352816581726\n",
      "epoch 33 loss: 0.5737260716756185\n",
      "epoch 34 loss: 0.5774616176287333\n",
      "epoch 35 loss: 0.5837179225285848\n",
      "epoch 36 loss: 0.5744550805091858\n",
      "epoch 37 loss: 0.5711612842877706\n",
      "epoch 38 loss: 0.5772343554496765\n",
      "epoch 39 loss: 0.5769876362482707\n",
      "epoch 40 loss: 0.5788685318628947\n",
      "epoch 41 loss: 0.5846232434908549\n",
      "epoch 42 loss: 0.5727217168807983\n",
      "epoch 43 loss: 0.5724881099065144\n",
      "epoch 44 loss: 0.5711854909261068\n",
      "epoch 45 loss: 0.5728197855949402\n",
      "epoch 46 loss: 0.5733821492195129\n",
      "epoch 47 loss: 0.5719491842587789\n",
      "epoch 48 loss: 0.5740819813410442\n",
      "epoch 49 loss: 0.5729275812307993\n",
      "epoch 50 loss: 0.5774596101442973\n",
      "epoch 51 loss: 0.5712381795247395\n",
      "epoch 52 loss: 0.5629463186264038\n",
      "epoch 53 loss: 0.561496567885081\n",
      "epoch 54 loss: 0.5730974980990092\n",
      "epoch 55 loss: 0.5779196235338847\n",
      "epoch 56 loss: 0.5619734816551208\n",
      "epoch 57 loss: 0.5575227225621542\n",
      "epoch 58 loss: 0.5631969447135925\n",
      "epoch 59 loss: 0.5647042285601298\n",
      "epoch 60 loss: 0.5536355532010396\n",
      "epoch 61 loss: 0.5701660571098328\n",
      "epoch 62 loss: 0.5948405186335246\n",
      "epoch 63 loss: 0.5634253854751587\n",
      "epoch 64 loss: 0.5544338814417521\n",
      "epoch 65 loss: 0.5998463799158732\n",
      "epoch 66 loss: 0.5619347320397695\n",
      "epoch 67 loss: 0.5501489283243816\n",
      "epoch 68 loss: 0.5611244088808696\n",
      "epoch 69 loss: 0.5586340835889181\n",
      "epoch 70 loss: 0.5825748688379924\n",
      "epoch 71 loss: 0.5513687998453776\n",
      "epoch 72 loss: 0.5390508775711059\n",
      "epoch 73 loss: 0.5472920603752136\n",
      "epoch 74 loss: 0.53981978225708\n",
      "epoch 75 loss: 0.54620618669192\n",
      "epoch 76 loss: 0.564917183081309\n",
      "epoch 77 loss: 0.5517888690630595\n",
      "epoch 78 loss: 0.5304666255315145\n",
      "epoch 79 loss: 0.518668231010437\n",
      "epoch 80 loss: 0.5348559236526489\n",
      "epoch 81 loss: 0.5178715330759684\n",
      "epoch 82 loss: 0.5414312562942505\n",
      "epoch 83 loss: 0.5247444802125295\n",
      "epoch 84 loss: 0.5160561201572418\n",
      "epoch 85 loss: 0.5053991950352986\n",
      "epoch 86 loss: 0.5248601112365723\n",
      "epoch 87 loss: 0.5021233983039856\n",
      "epoch 88 loss: 0.4975632348060608\n",
      "epoch 89 loss: 0.48279342881838483\n",
      "epoch 90 loss: 0.5220249969164531\n",
      "epoch 91 loss: 0.5091356711387635\n",
      "epoch 92 loss: 0.4935981837908427\n",
      "epoch 93 loss: 0.534609200557073\n",
      "epoch 94 loss: 0.5021504310766856\n",
      "epoch 95 loss: 0.48206995058059693\n",
      "epoch 96 loss: 0.4707024947007497\n",
      "epoch 97 loss: 0.4890097190539042\n",
      "epoch 98 loss: 0.45559770496686297\n",
      "epoch 99 loss: 0.4865198624928792\n",
      "epoch 100 loss: 0.4773899262746175\n",
      "epoch 101 loss: 0.4604389489491781\n",
      "epoch 102 loss: 0.47944945136706035\n",
      "epoch 103 loss: 0.44108390307426454\n",
      "epoch 104 loss: 0.44130099193255107\n",
      "epoch 105 loss: 0.48483423837025963\n",
      "epoch 106 loss: 0.4701167759895325\n",
      "epoch 107 loss: 0.4608094003200531\n",
      "epoch 108 loss: 0.43217522629102073\n",
      "epoch 109 loss: 0.4516188793182373\n",
      "epoch 110 loss: 0.44582110484441123\n",
      "epoch 111 loss: 0.44104068231582644\n",
      "epoch 112 loss: 0.4279323019981384\n",
      "epoch 113 loss: 0.4480740423997243\n",
      "epoch 114 loss: 0.4483719449043274\n",
      "epoch 115 loss: 0.4200543830394745\n",
      "epoch 116 loss: 0.42531521677970885\n",
      "epoch 117 loss: 0.40906055172284445\n",
      "epoch 118 loss: 0.447401954571406\n",
      "epoch 119 loss: 0.39966974512736003\n",
      "epoch 120 loss: 0.41970702052116393\n",
      "epoch 121 loss: 0.4058467812538147\n",
      "epoch 122 loss: 0.4175931412378947\n",
      "epoch 123 loss: 0.4578660384019216\n",
      "epoch 124 loss: 0.433340247631073\n",
      "epoch 125 loss: 0.4112130481402079\n",
      "epoch 126 loss: 0.3922294059197108\n",
      "epoch 127 loss: 0.39832419880231223\n",
      "epoch 128 loss: 0.37816917355855306\n",
      "epoch 129 loss: 0.4447840040524801\n",
      "epoch 130 loss: 0.4007658054033915\n",
      "epoch 131 loss: 0.38618577241897584\n",
      "epoch 132 loss: 0.381559263865153\n",
      "epoch 133 loss: 0.39244498205184936\n",
      "epoch 134 loss: 0.39997682960828146\n",
      "epoch 135 loss: 0.39549251770973204\n",
      "epoch 136 loss: 0.39158757575352987\n",
      "epoch 137 loss: 0.3671797674496969\n",
      "epoch 138 loss: 0.3772841895421346\n",
      "epoch 139 loss: 0.36203645006815593\n",
      "epoch 140 loss: 0.36367859156926474\n",
      "epoch 141 loss: 0.42987059768040975\n",
      "epoch 142 loss: 0.4165584590435028\n",
      "epoch 143 loss: 0.36944855213165284\n",
      "epoch 144 loss: 0.3719244208335876\n",
      "epoch 145 loss: 0.37187813210487364\n",
      "epoch 146 loss: 0.38079523928960163\n",
      "epoch 147 loss: 0.35357255033651985\n",
      "epoch 148 loss: 0.3449105358918508\n",
      "epoch 149 loss: 0.35205102427800494\n",
      "epoch 150 loss: 0.35129191080729166\n",
      "epoch 151 loss: 0.34464922030766804\n",
      "epoch 152 loss: 0.347299897869428\n",
      "epoch 153 loss: 0.3356084152062734\n",
      "epoch 154 loss: 0.378205171028773\n",
      "epoch 155 loss: 0.39756464060147606\n",
      "epoch 156 loss: 0.3676716718673706\n",
      "epoch 157 loss: 0.35870226764678953\n",
      "epoch 158 loss: 0.35632107281684877\n",
      "epoch 159 loss: 0.34539097801844276\n",
      "epoch 160 loss: 0.33424918103218076\n",
      "epoch 161 loss: 0.35329939099152885\n",
      "epoch 162 loss: 0.39475432523091636\n",
      "epoch 163 loss: 0.3904477558930715\n",
      "epoch 164 loss: 0.37020234910647076\n",
      "epoch 165 loss: 0.35129231643676756\n",
      "epoch 166 loss: 0.3373955890337626\n",
      "epoch 167 loss: 0.3355007725556691\n",
      "epoch 168 loss: 0.3389505871136983\n",
      "epoch 169 loss: 0.3561648234128952\n",
      "epoch 170 loss: 0.3374204982916514\n",
      "epoch 171 loss: 0.3367826155821482\n",
      "epoch 172 loss: 0.36853782486915587\n",
      "epoch 173 loss: 0.32543843452135723\n",
      "epoch 174 loss: 0.3252878265380859\n",
      "epoch 175 loss: 0.3301526031494141\n",
      "epoch 176 loss: 0.34156459228197733\n",
      "epoch 177 loss: 0.3394577030738195\n",
      "epoch 178 loss: 0.35769605175654096\n",
      "epoch 179 loss: 0.3291766355832418\n",
      "epoch 180 loss: 0.3173396073182424\n",
      "epoch 181 loss: 0.3224522171020508\n",
      "epoch 182 loss: 0.30912411204973855\n",
      "epoch 183 loss: 0.31074362993240356\n",
      "epoch 184 loss: 0.31559738198916115\n",
      "epoch 185 loss: 0.3178026864528656\n",
      "epoch 186 loss: 0.32340543365478513\n",
      "epoch 187 loss: 0.33574873781204223\n",
      "epoch 188 loss: 0.3201065061887105\n",
      "epoch 189 loss: 0.31229195117950437\n",
      "epoch 190 loss: 0.31693139735857645\n",
      "epoch 191 loss: 0.33162510005633034\n",
      "epoch 192 loss: 0.3324294075965881\n",
      "epoch 193 loss: 0.32100088397661847\n",
      "epoch 194 loss: 0.35267313822110496\n",
      "epoch 195 loss: 0.34676847330729166\n",
      "epoch 196 loss: 0.31766086332003274\n",
      "epoch 197 loss: 0.3177347199122111\n",
      "epoch 198 loss: 0.3133095103899638\n",
      "epoch 199 loss: 0.31135205229123436\n",
      "epoch 200 loss: 0.3204688758055369\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(1, 201):\n",
    "    epoch_loss = 0.0\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.      \n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y.squeeze())  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        epoch_loss += out.shape[0] * loss.item()\n",
    "    print(f'epoch {epoch} loss: {epoch_loss/len(train_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test_loader:\n",
    "    y_true.extend(data.y.squeeze())\n",
    "    y_pred.extend(model(data.x, data.edge_index, data.batch).argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[203,  40],\n",
       "       [ 26, 231]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/io/pretrained_reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_dict = {\n",
    "        \"adj\": all_adjs,\n",
    "        \"feat\": all_feats,\n",
    "        \"label\": all_labels,\n",
    "        \"pred\": np.expand_dims(predictions, axis=0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cg_dict, '/io/cg_reddit')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
