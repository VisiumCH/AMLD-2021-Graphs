{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Explainer\n",
    "\n",
    "The purpose of this notebook is to present GNN Explainer, a general, model-agnostic approach for providing inter-\n",
    "pretable explanations for predictions of any GNN-based model on any graph-based\n",
    "machine learning task.\n",
    "\n",
    "The notebook is organized as follows:\n",
    "\n",
    "* Brief theoretical recap on GNN-EXPLAINER\n",
    "* Train your GNN-EXPLAINER to explain graph classification predictions\n",
    "* Visualize and understand the propose explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your GNN Explainer!\n",
    "\n",
    "In this section we will build together the main module used by the explainer, which is implemented in the **ExplainModule class**. This class contains several methods, in particular:\n",
    "\n",
    "**construct_feat_mask**: initializes the feature mask that will be learned by the explainer\n",
    "\n",
    "**construct edge_mask**: initializes the edge mask that will be learne by the explainer\n",
    "\n",
    "**mask_adj**: computes the masked adjacency matrices of the graph whose prediction we want to explain\n",
    "\n",
    "**mask_density**: computes mask density as (sum masked entried)/(original sum of entries)\n",
    "\n",
    "**forward**: returns the model prediction (and edge attention, if available), based on the current edge and feature masks.\n",
    "\n",
    "**loss**: computes the loss function as explained in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorboardX.utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainModule(nn.Module):\n",
    "    def __init__(\n",
    "        self, adj, x, model, label, args, graph_idx=0, writer=None, use_sigmoid=True\n",
    "    ):\n",
    "        super(ExplainModule, self).__init__()\n",
    "        self.adj = adj\n",
    "        self.x = x\n",
    "        self.model = model\n",
    "        self.label = label\n",
    "        self.graph_idx = graph_idx\n",
    "        self.args = args\n",
    "        self.writer = writer\n",
    "        self.mask_act = args.mask_act\n",
    "        self.use_sigmoid = use_sigmoid\n",
    "        self.graph_mode = True\n",
    "        # Relative weights for the terms in the loss function.\n",
    "        self.coeffs = {\n",
    "            \"size\": 0.005,\n",
    "            \"feat_size\": 1.0,\n",
    "            \"ent\": 1.0,\n",
    "            \"feat_ent\": 0.1,\n",
    "            \"grad\": 0,\n",
    "            \"lap\": 1.0,\n",
    "        }\n",
    "        num_nodes = adj.size()[1]\n",
    "        init_strategy = \"normal\"\n",
    "        # Initialize the edge mask to be optimized.\n",
    "        self.mask, self.mask_bias = self.construct_edge_mask(\n",
    "            num_nodes, init_strategy=init_strategy\n",
    "        )\n",
    "        # Initialize the feature mask to be optimized.\n",
    "        self.feat_mask = self.construct_feat_mask(x.size(-1), init_strategy=\"constant\")\n",
    "        params = [self.mask, self.feat_mask]\n",
    "        if self.mask_bias is not None:\n",
    "            params.append(self.mask_bias)\n",
    "        # For masking diagonal entries.\n",
    "        self.diag_mask = torch.ones(num_nodes, num_nodes) - torch.eye(num_nodes)\n",
    "        if args.gpu:\n",
    "            self.diag_mask = self.diag_mask.cuda()\n",
    "\n",
    "        self.scheduler, self.optimizer = train_utils.build_optimizer(args, params)\n",
    "\n",
    "    def construct_feat_mask(self, feat_dim, init_strategy=\"normal\"):\n",
    "        \"\"\"Initialize the feature mask. init_strategy is a string specifying\n",
    "        the chosen initialization strategy (can be 'costant' or 'normal'.)\n",
    "        \"\"\"\n",
    "        mask = nn.Parameter(torch.FloatTensor(feat_dim))\n",
    "        if init_strategy == \"normal\":\n",
    "            std = 0.1\n",
    "            with torch.no_grad():\n",
    "                mask.normal_(1.0, std)\n",
    "        elif init_strategy == \"constant\":\n",
    "            with torch.no_grad():\n",
    "                nn.init.constant_(mask, 0.0)\n",
    "        return mask\n",
    "\n",
    "    def construct_edge_mask(self, num_nodes, init_strategy=\"normal\", const_val=1.0):\n",
    "        \"\"\"Initialize the edge mask. init_strategy is a string specifying\n",
    "        the chosen initialization strategy (eg 'costant' or 'normal'.)\n",
    "        \"\"\"\n",
    "        mask = nn.Parameter(torch.FloatTensor(num_nodes, num_nodes))\n",
    "        if init_strategy == \"normal\":\n",
    "            std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "                2.0 / (num_nodes + num_nodes)\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                mask.normal_(1.0, std)\n",
    "        elif init_strategy == \"const\":\n",
    "            nn.init.constant_(mask, const_val)\n",
    "        if self.args.mask_bias:\n",
    "            mask_bias = nn.Parameter(torch.FloatTensor(num_nodes, num_nodes))\n",
    "            nn.init.constant_(mask_bias, 0.0)\n",
    "        else:\n",
    "            mask_bias = None\n",
    "\n",
    "        return mask, mask_bias\n",
    "\n",
    "    def _masked_adj(self):\n",
    "        \"\"\"Computes the masked adjacency matrix of the graph. Since\n",
    "        we work with undirected graphs, we make the mask symmetric.\n",
    "        Self-loops are also excluded using a diagonal mask.\n",
    "        \"\"\"\n",
    "        sym_mask = self.mask\n",
    "        if self.mask_act == \"sigmoid\":\n",
    "            sym_mask = torch.sigmoid(self.mask)\n",
    "        elif self.mask_act == \"ReLU\":\n",
    "            sym_mask = nn.ReLU()(self.mask)\n",
    "        sym_mask = (sym_mask + sym_mask.t()) / 2\n",
    "        adj = self.adj.cuda() if self.args.gpu else self.adj\n",
    "        masked_adj = adj * sym_mask\n",
    "        if self.args.mask_bias:\n",
    "            bias = (self.mask_bias + self.mask_bias.t()) / 2\n",
    "            bias = nn.ReLU6()(bias * 6) / 6\n",
    "            masked_adj += (bias + bias.t()) / 2\n",
    "        return masked_adj * self.diag_mask\n",
    "\n",
    "    def mask_density(self):\n",
    "        mask_sum = torch.sum(self._masked_adj()).cpu()\n",
    "        adj_sum = torch.sum(self.adj)\n",
    "        return mask_sum / adj_sum\n",
    "\n",
    "    def forward(self, mask_features=True, marginalize=False):\n",
    "        \"\"\"Computes the model prediction on the masked graph with masked features.\n",
    "        Returns the model predictions and adjacency attention (if available).\n",
    "        \"\"\"\n",
    "        x = self.x.cuda() if self.args.gpu else self.x\n",
    "        self.masked_adj = self._masked_adj()\n",
    "        if mask_features:\n",
    "            feat_mask = (\n",
    "                torch.sigmoid(self.feat_mask) if self.use_sigmoid else self.feat_mask\n",
    "            )\n",
    "            if marginalize:\n",
    "                std_tensor = torch.ones_like(x, dtype=torch.float) / 2\n",
    "                mean_tensor = torch.zeros_like(x, dtype=torch.float) - x\n",
    "                z = torch.normal(mean=mean_tensor, std=std_tensor)\n",
    "                x = x + z * (1 - feat_mask)\n",
    "            else:\n",
    "                x = x * feat_mask\n",
    "\n",
    "        ypred, adj_att = self.model(x, self.masked_adj)\n",
    "        res = nn.Softmax(dim=0)(ypred[0])\n",
    "\n",
    "        return res, adj_att\n",
    "\n",
    "    def loss(self, pred, epoch):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred: prediction made by current model (with current mask).\n",
    "            epoch: training epoch.\n",
    "        \"\"\"\n",
    "        # Prediction loss.\n",
    "        gt_label = self.label\n",
    "        logit = pred[gt_label]\n",
    "        pred_loss = -torch.log(logit)\n",
    "        # Adjacency mask size loss.\n",
    "        mask = self.mask\n",
    "        if self.mask_act == \"sigmoid\":\n",
    "            mask = torch.sigmoid(self.mask)\n",
    "        elif self.mask_act == \"ReLU\":\n",
    "            mask = nn.ReLU()(self.mask)\n",
    "        size_loss = self.coeffs[\"size\"] * torch.sum(mask)\n",
    "        # Feature mask size loss.\n",
    "        feat_mask = (\n",
    "            torch.sigmoid(self.feat_mask) if self.use_sigmoid else self.feat_mask\n",
    "        )\n",
    "        feat_size_loss = self.coeffs[\"feat_size\"] * torch.mean(feat_mask)\n",
    "        # Adjacency mask entropy loss.\n",
    "        mask_ent = -mask * torch.log(mask) - (1 - mask) * torch.log(1 - mask)\n",
    "        mask_ent_loss = self.coeffs[\"ent\"] * torch.mean(mask_ent)\n",
    "        # Feature mask entropy loss.\n",
    "        feat_mask_ent = -feat_mask * torch.log(feat_mask) - (1 - feat_mask) * torch.log(\n",
    "            1 - feat_mask\n",
    "        )\n",
    "        feat_mask_ent_loss = self.coeffs[\"feat_ent\"] * torch.mean(feat_mask_ent)\n",
    "        # Total loss.\n",
    "        loss = pred_loss + size_loss + mask_ent_loss + feat_size_loss\n",
    "\n",
    "        # Log data to tensorboard.\n",
    "        if self.writer is not None:\n",
    "            self.writer.add_scalar(\"optimization/size_loss\", size_loss, epoch)\n",
    "            self.writer.add_scalar(\"optimization/feat_size_loss\", feat_size_loss, epoch)\n",
    "            self.writer.add_scalar(\"optimization/mask_ent_loss\", mask_ent_loss, epoch)\n",
    "            self.writer.add_scalar(\n",
    "                \"optimization/feat_mask_ent_loss\", mask_ent_loss, epoch\n",
    "            )\n",
    "            self.writer.add_scalar(\"optimization/pred_loss\", pred_loss, epoch)\n",
    "            # self.writer.add_scalar(\"optimization/lap_loss\", lap_loss, epoch)\n",
    "            self.writer.add_scalar(\"optimization/overall_loss\", loss, epoch)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our explainer, we then use the trainExplainer function, implemented in the explainer.py file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "\n",
    "import src.GNNexplainer.configs_explainer as configs_explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset DATASET] [--bmname BMNAME]\n",
      "                             [--pkl PKL_FNAME] [--opt OPT]\n",
      "                             [--opt-scheduler OPT_SCHEDULER]\n",
      "                             [--opt-restart OPT_RESTART]\n",
      "                             [--opt-decay-step OPT_DECAY_STEP]\n",
      "                             [--opt-decay-rate OPT_DECAY_RATE] [--lr LR]\n",
      "                             [--clip CLIP] [--clean-log] [--logdir LOGDIR]\n",
      "                             [--ckptdir CKPTDIR] [--cuda CUDA] [--gpu]\n",
      "                             [--epochs NUM_EPOCHS] [--hidden-dim HIDDEN_DIM]\n",
      "                             [--output-dim OUTPUT_DIM]\n",
      "                             [--num-gc-layers NUM_GC_LAYERS] [--bn]\n",
      "                             [--dropout DROPOUT] [--nobias] [--no-writer]\n",
      "                             [--mask-act MASK_ACT] [--mask-bias]\n",
      "                             [--explain-node EXPLAIN_NODE]\n",
      "                             [--graph-idx GRAPH_IDX] [--graph-mode]\n",
      "                             [--multigraph-class MULTIGRAPH_CLASS]\n",
      "                             [--multinode-class MULTINODE_CLASS]\n",
      "                             [--align-steps ALIGN_STEPS] [--method METHOD]\n",
      "                             [--name-suffix NAME_SUFFIX]\n",
      "                             [--explainer-suffix EXPLAINER_SUFFIX]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/camilla.casamento/.local/share/jupyter/runtime/kernel-1ffa5e25-bc55-47f4-970d-8bc027e508c5.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "prog_args = configs_explainer.explainer_arg_parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-755f875ce953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprog_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigs_explainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer_arg_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AMLD-2021-Graphs/src/GNNexplainer/configs_explainer.py\u001b[0m in \u001b[0;36mexplainer_arg_parse\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mmultinode_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1759\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2506\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2507\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2495\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a configuration\n",
    "\n",
    "\n",
    "\n",
    "if prog_args.gpu:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = prog_args.cuda\n",
    "    print(\"CUDA\", prog_args.cuda)\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Configure the logging directory\n",
    "if prog_args.writer:\n",
    "    path = os.path.join(prog_args.logdir, io_utils.gen_explainer_prefix(prog_args))\n",
    "    if os.path.isdir(path) and prog_args.clean_log:\n",
    "        print(\"Removing existing log dir: \", path)\n",
    "        if (\n",
    "            not input(\"Are you sure you want to remove this directory? (y/n): \")\n",
    "            .lower()\n",
    "            .strip()[:1]\n",
    "            == \"y\"\n",
    "        ):\n",
    "            sys.exit(1)\n",
    "        shutil.rmtree(path)\n",
    "    writer = SummaryWriter(path)\n",
    "else:\n",
    "    writer = None\n",
    "\n",
    "# Load a model checkpoint\n",
    "ckpt = io_utils.load_ckpt(prog_args)\n",
    "cg_dict = ckpt[\"cg\"]  # get computation graph\n",
    "input_dim = cg_dict[\"feat\"].shape[2]\n",
    "num_classes = cg_dict[\"pred\"].shape[2]\n",
    "print(\"Loaded model from {}\".format(prog_args.ckptdir))\n",
    "print(\"input dim: \", input_dim, \"; num classes: \", num_classes)\n",
    "\n",
    "# build model\n",
    "print(\"Method: \", prog_args.method)\n",
    "\n",
    "# Explain Graph prediction\n",
    "model = models.GcnEncoderGraph(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=prog_args.hidden_dim,\n",
    "    embedding_dim=prog_args.output_dim,\n",
    "    label_dim=num_classes,\n",
    "    num_layers=prog_args.num_gc_layers,\n",
    "    bn=prog_args.bn,\n",
    "    args=prog_args,\n",
    ")\n",
    "if prog_args.gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "# Load state_dict (obtained by model.state_dict() when saving checkpoint)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model = model.eval()\n",
    "\n",
    "# Extract the data relative to the chosen graph.\n",
    "adj = cg_dict[\"adj\"]\n",
    "feat = cg_dict[\"feat\"]\n",
    "label = cg_dict[\"label\"]\n",
    "pred = cg_dict[\"pred\"]\n",
    "\n",
    "graph_idx = prog_args.graph_idx\n",
    "sub_adj = adj[graph_idx]\n",
    "sub_feat = feat[graph_idx, :]\n",
    "sub_label = label[graph_idx]\n",
    "neighbors = np.asarray(range(adj.shape[0]))\n",
    "\n",
    "sub_adj = np.expand_dims(sub_adj, axis=0)\n",
    "sub_feat = np.expand_dims(sub_feat, axis=0)\n",
    "\n",
    "adj = torch.tensor(sub_adj, dtype=torch.float)\n",
    "x = torch.tensor(sub_feat, requires_grad=True, dtype=torch.float)\n",
    "label = torch.tensor(sub_label, dtype=torch.long)\n",
    "\n",
    "# Create explainer\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    adj=adj,\n",
    "    x=x,\n",
    "    label=label,\n",
    "    args=prog_args,\n",
    "    writer=writer,\n",
    "    graph_idx=prog_args.graph_idx,\n",
    ")\n",
    "\n",
    "# Run explainer.\n",
    "train_explainer(\n",
    "    explainer=explainer, pred=pred, args=prog_args, graph_idx=prog_args.graph_idx\n",
    ")\n",
    "io_utils.plot_cmap_tb(writer, \"tab20\", 20, \"tab20_cmap\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This notebook is designed to visualize the results of the GNN Explainer.\n",
    "\n",
    "Use it after one has trained the model using train.py, and has run the explainer optimization (explainer_main.py).\n",
    "The main purpose is to visualize the trained mask by interactively tuning the threshold. In many scientific applications, the explanation size is unknown a priori. This tool can help user visualize the selected subgraph, with respect to different values of the thresholds, and find the right size for a good explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring the experiment you want to visualize. These values should match the configuration:\n",
    "\n",
    "> TODO: Unify configuration of experiments in yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = '../src/GNNexplainer/log/'\n",
    "expdir = 'REDDIT-BINARY_base_h20_o20_explain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the produced masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(os.path.join(logdir, expdir))\n",
    "dirs = os.listdir(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked_adj_REDDIT-BINARY_base_h20_o20_explainnode_idx_0graph_idx_3.npy\n"
     ]
    }
   ],
   "source": [
    "masks = []\n",
    "# This would print all the files and directories\n",
    "for file in dirs:\n",
    "    if file.split('.')[-1] == 'npy':\n",
    "        print(file)\n",
    "        masks.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility to save masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.readwrite import json_graph\n",
    "\n",
    "def save_mask(G, fname, fmt='json', suffix=''):\n",
    "    pth = os.path.join(logdir, expdir, fname+'-filt-'+suffix+'.'+fmt)\n",
    "    if fmt == 'json':\n",
    "        dt = json_graph.node_link_data(G)\n",
    "        with open(pth, 'w') as f:\n",
    "            json.dump(dt, f)\n",
    "    elif fmt == 'pdf':\n",
    "        plt.savefig(pth)\n",
    "    elif fmt == 'npy':\n",
    "        np.save(pth, nx.to_numpy_array(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_adjacency_full(mask, ax=None):\n",
    "    adj = np.load(os.path.join(logdir, expdir, mask), allow_pickle=True)\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "        plt.imshow(adj);\n",
    "    else:\n",
    "        ax.imshow(adj)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_adjacency_full(mask, ax=None):\n",
    "    adj = np.load(os.path.join(logdir, expdir, mask), allow_pickle=True)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0726735fbc94f298df471512c727cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='thresh', max=1.5, min=-0.5), Output()), _dom_classes…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filt_adj = read_adjacency_full(masks[0])\n",
    "@interact\n",
    "def filter_adj(thresh=0.5):\n",
    "    filt_adj[filt_adj<thresh] = 0\n",
    "    return filt_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight-based threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd18bc2358dc443ead957730054ebabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='thresh', max=1.0, step=0.01), Output()), _dom_classe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EDIT THIS INDEX\n",
    "MASK_IDX = 0\n",
    "# EDIT THIS INDEX\n",
    "\n",
    "m = masks[MASK_IDX]\n",
    "adj = read_adjacency_full(m)\n",
    "\n",
    "\n",
    "@interact(thresh=widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.01))\n",
    "def plot_interactive(thresh=0.5):\n",
    "    filt_adj = read_adjacency_full(m)\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "    plt.title(str(m));\n",
    "\n",
    "    # Full adjacency\n",
    "    ax1.set_title('Full Adjacency mask')\n",
    "    adj = show_adjacency_full(m, ax=ax1);\n",
    "    \n",
    "    # Filtered adjacency\n",
    "    filt_adj[filt_adj<thresh] = 0\n",
    "    ax2.set_title('Filtered Adjacency mask');\n",
    "    ax2.imshow(filt_adj);\n",
    "    \n",
    "    # Plot subgraph\n",
    "    ax3.set_title(\"Subgraph\")\n",
    "    G_ = nx.from_numpy_array(adj)\n",
    "    G  = nx.from_numpy_array(filt_adj)\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    nx.draw(G, ax=ax3)\n",
    "    save_mask(G, fname=m, fmt='json')\n",
    "    \n",
    "    print(\"Removed {} edges -- K = {} remain.\".format(G_.number_of_edges()-G.number_of_edges(), G.number_of_edges()))\n",
    "    print(\"Removed {} nodes -- K = {} remain.\".format(G_.number_of_nodes()-G.number_of_nodes(), G.number_of_nodes()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
